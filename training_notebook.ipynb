{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16d60062-2607-4f54-9d60-bffe214b89e5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "# For OpenCV-based face detection\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from tensorflow.keras.layers import (\n",
    "    Conv2D,\n",
    "    MaxPooling2D,\n",
    "    Dense,\n",
    "    Flatten,\n",
    "    Dropout,\n",
    "    BatchNormalization,\n",
    "    GlobalAveragePooling2D,\n",
    "    Reshape\n",
    ")\n",
    "from tensorflow.keras.layers import multiply\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "# Suppress warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore', category=UserWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3ddb3db",
   "metadata": {},
   "source": [
    "# Imported all relevent libraries \n",
    "# Loading face data "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87ad24de",
   "metadata": {},
   "source": [
    "#read in image data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8de03062-301f-4fb4-bdf4-6500c93667c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to your Haar Cascade XML file\n",
    "HAAR_CASCADE_PATH = '/Users/loki/Desktop/worksurface/ai_lab/REPOS/vision/haarcascade_frontalface_default.xml'\n",
    "face_cascade = cv2.CascadeClassifier(HAAR_CASCADE_PATH)\n",
    "\n",
    "EYE_CASCADE_PATH = '/Users/loki/Desktop/worksurface/ai_lab/REPOS/vision/haarcascade_eye.xml'\n",
    "eye_cascade = cv2.CascadeClassifier(EYE_CASCADE_PATH)\n",
    "if eye_cascade.empty():\n",
    "    raise IOError(\"Could not load Haar cascade for eyes.\")\n",
    "\n",
    "def detect_faces(pil_image, min_size=60):\n",
    "    #Detect faces using Haar Cascade. Return a list of PIL Images for each face\n",
    "    #that meets the minimum bounding box size.\n",
    "\n",
    "    open_cv_image = np.array(pil_image.convert('RGB'))[:, :, ::-1]\n",
    "    gray = cv2.cvtColor(open_cv_image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    faces_bboxes = face_cascade.detectMultiScale(\n",
    "        gray,\n",
    "        scaleFactor=1.1,\n",
    "        minNeighbors=5,\n",
    "        minSize=(30, 30),          # or you can tweak this param as well\n",
    "        flags=cv2.CASCADE_SCALE_IMAGE\n",
    "    )\n",
    "\n",
    "    face_images = []\n",
    "    for (x, y, w, h) in faces_bboxes:\n",
    "        # Filter out partial faces by bounding box dimensions\n",
    "        if w < min_size or h < min_size:\n",
    "            # If bounding box is too small, skip\n",
    "            continue\n",
    "        \n",
    "        # Crop the face region\n",
    "        face_bgr = open_cv_image[y:y+h, x:x+w]\n",
    "        face_pil = Image.fromarray(face_bgr[:, :, ::-1], mode='RGB')\n",
    "        \n",
    "        # Resize/crop to 170×170\n",
    "        face_pil = face_pil.resize((170, 170), Image.Resampling.LANCZOS)\n",
    "        \n",
    "        face_images.append(face_pil)\n",
    "\n",
    "    return face_images\n",
    "      \n",
    "def detect_faces_with_eye_check(pil_image, min_size=60, require_eyes=True):\n",
    "    \"\"\"\n",
    "    Detect faces using Haar Cascade. Optionally require each detected face\n",
    "    to have at least one eye detected within the bounding box.\n",
    "    \n",
    "    Args:\n",
    "        pil_image: A PIL image.\n",
    "        min_size (int): Minimum width/height of a face bounding box.\n",
    "        require_eyes (bool): Whether to filter out bounding boxes with no eyes.\n",
    "    \n",
    "    Returns:\n",
    "        face_images (list): A list of PIL Images (170x170).\n",
    "    \"\"\"\n",
    "    # Convert PIL -> OpenCV format (BGR)\n",
    "    open_cv_image = np.array(pil_image.convert('RGB'))[:, :, ::-1]\n",
    "    gray = cv2.cvtColor(open_cv_image, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # Detect face bounding boxes\n",
    "    faces_bboxes = face_cascade.detectMultiScale(\n",
    "        gray,\n",
    "        scaleFactor=1.1,\n",
    "        minNeighbors=5,\n",
    "        minSize=(30, 30),\n",
    "        flags=cv2.CASCADE_SCALE_IMAGE\n",
    "    )\n",
    "    \n",
    "    face_images = []\n",
    "    for (x, y, w, h) in faces_bboxes:\n",
    "        # 1. Filter out if bounding box too small:\n",
    "        if w < min_size or h < min_size:\n",
    "            continue\n",
    "        \n",
    "        # 2. (Optional) Eye check: detect eyes within this face region\n",
    "        if require_eyes:\n",
    "            faceROI_gray = gray[y:y+h, x:x+w]\n",
    "            eyes = eye_cascade.detectMultiScale(faceROI_gray)\n",
    "            \n",
    "            # If no eyes detected, skip\n",
    "            if len(eyes) == 0:\n",
    "                continue\n",
    "        \n",
    "        # Crop the face region\n",
    "        face_bgr = open_cv_image[y:y+h, x:x+w]\n",
    "        face_pil = Image.fromarray(face_bgr[:, :, ::-1], mode='RGB')\n",
    "        \n",
    "        # Resize/crop to 170×170\n",
    "        face_pil = face_pil.resize((170, 170), Image.Resampling.LANCZOS)\n",
    "        \n",
    "        face_images.append(face_pil)\n",
    "\n",
    "    return face_images\n",
    "\n",
    "def process_directory(directory):\n",
    "    total_data = {'X': [], 'Y': [], 'raw': []}\n",
    "\n",
    "    for filename in os.listdir(directory):\n",
    "        if filename.startswith('.'):\n",
    "            continue\n",
    "        \n",
    "        if filename.startswith('s'):\n",
    "            label = 1  # Squint\n",
    "        elif filename.startswith('us'):\n",
    "            label = 0  # Not squint\n",
    "        else:\n",
    "            continue\n",
    "        \n",
    "        full_path = os.path.join(directory, filename)\n",
    "        \n",
    "        try:\n",
    "            img = Image.open(full_path)\n",
    "            \n",
    "            # Use the new face+eye detection\n",
    "            faces = detect_faces_with_eye_check(img, min_size=60, require_eyes=True)\n",
    "            \n",
    "            if len(faces) == 0:\n",
    "                print(f\"No valid (full) faces detected in {filename}. Skipping.\")\n",
    "                continue\n",
    "            \n",
    "            for face in faces:\n",
    "                face_gray = face.convert('L')\n",
    "                face_raw = np.array(face_gray)\n",
    "                \n",
    "                total_data['raw'].append(face_raw)\n",
    "                \n",
    "                face_flattened = face_raw.flatten()\n",
    "                total_data['X'].append(face_flattened)\n",
    "                total_data['Y'].append(label)\n",
    "        \n",
    "        except IOError:\n",
    "            print(f\"Cannot open image file: {filename}\")\n",
    "\n",
    "    if not total_data['X']:\n",
    "        print(\"No valid images or faces found in directory.\")\n",
    "        return total_data\n",
    "\n",
    "    # Pad flattened arrays to the same length\n",
    "    max_len = max(len(x) for x in total_data['X'])\n",
    "    X_padded = [np.pad(x, (0, max_len - len(x))) for x in total_data['X']]\n",
    "    \n",
    "    total_data['X'] = np.array(X_padded, dtype=np.float32)\n",
    "    total_data['Y'] = np.array(total_data['Y'], dtype=np.int32)\n",
    "\n",
    "    return total_data\n",
    "\n",
    "def view_images(dict_obj, num_images):\n",
    "    \"\"\"\n",
    "    Display up to n raw grayscale images (each 170x170).\n",
    "    \"\"\"\n",
    "    num_to_show = min(num_images, len(dict_obj['raw']))\n",
    "    for i in range(num_to_show):\n",
    "        image_2d = dict_obj['raw'][i]\n",
    "        plt.imshow(image_2d, cmap='gray')\n",
    "        plt.title(f\"Face {i} - Label {dict_obj['Y'][i]}\")\n",
    "        plt.show()\n",
    "\n",
    "def plot_label_distribution(df):\n",
    "    \"\"\"\n",
    "    Plots and prints the distribution of squint (1) vs. not squint (0) \n",
    "    in the given DataFrame. Assumes 'Y' is the label column.\n",
    "    \"\"\"\n",
    "    # 1. Print counts and percentages\n",
    "    label_counts = df['Y'].value_counts()\n",
    "    label_percentages = df['Y'].value_counts(normalize=True) * 100\n",
    "\n",
    "    print(\"Label Counts:\")\n",
    "    print(label_counts)\n",
    "    print(\"\\nLabel Percentages (%):\")\n",
    "    print(label_percentages)\n",
    "\n",
    "    # 2. Plot the distribution\n",
    "    sns.set_style(\"whitegrid\")\n",
    "    plt.figure(figsize=(6, 4))\n",
    "    ax = sns.countplot(x='Y', data=df, palette='viridis')\n",
    "    ax.set_xticklabels(['Not Squint (0)', 'Squint (1)'])\n",
    "    plt.title(\"Distribution of Squint vs. Not Squint\")\n",
    "    plt.xlabel(\"Label\")\n",
    "    plt.ylabel(\"Count\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c0d9b57",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_no_face_rows(df):\n",
    "    \"\"\"\n",
    "    Removes rows from df where 'raw' is None, empty, or doesn't match expected shape (170, 170).\n",
    "    Returns a filtered copy of df.\n",
    "    \"\"\"\n",
    "    def has_valid_face(arr):\n",
    "        # Must not be None\n",
    "        if arr is None:\n",
    "            return False\n",
    "        \n",
    "        # Must be at least 2D\n",
    "        if arr.ndim != 2:\n",
    "            return False\n",
    "        \n",
    "        # Must be the right shape for a 170x170 grayscale face\n",
    "        if arr.shape != (170, 170):\n",
    "            return False\n",
    "        \n",
    "        # Optionally, skip arrays of all zeros (completely black)\n",
    "        if arr.sum() == 0:\n",
    "            return False\n",
    "        \n",
    "        return True\n",
    "\n",
    "    mask = df['raw'].apply(has_valid_face)\n",
    "    df_filtered = df[mask].copy()\n",
    "    removed = len(df) - len(df_filtered)\n",
    "    print(f\"Removed {removed} rows that do not contain a valid face.\")\n",
    "    return df_filtered\n",
    "\n",
    "def load_face_data():\n",
    "    # Example directory path\n",
    "    directory = '/Users/loki/Desktop/worksurface/ai_lab/REPOS/vision/face-squint'\n",
    "    \n",
    "    dict_obj = process_directory(directory)\n",
    "\n",
    "    if len(dict_obj['X']) > 0:\n",
    "        df = pd.DataFrame({\n",
    "            'X': list(dict_obj['X']),    # flattened, padded arrays\n",
    "            'Y': dict_obj['Y'],          # labels\n",
    "            'raw': list(dict_obj['raw']) # each is a 2D 170x170\n",
    "        })\n",
    "        \n",
    "        print(f\"Total faces before cleaning: {len(df)}\")\n",
    "        \n",
    "        # Clean out rows that do not actually contain a face\n",
    "        df = remove_no_face_rows(df)\n",
    "        \n",
    "        print(f\"Total faces after cleaning: {len(df)}\")\n",
    "        print(df.head())\n",
    "        \n",
    "        # View some images (optional - might want to check if any data is left)\n",
    "        if not df.empty:\n",
    "            # Create a \"dict_obj\" style structure so `view_images` can still work\n",
    "            cleaned_dict_obj = {\n",
    "                'raw': list(df['raw']),\n",
    "                'Y': df['Y'].values\n",
    "            }\n",
    "            view_images(cleaned_dict_obj, 50)\n",
    "            plot_label_distribution(df)\n",
    "        \n",
    "        return df\n",
    "    else:\n",
    "        print(\"No data to display.\")\n",
    "        return\n",
    "\n",
    "faces=load_face_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65b069fa-7ed5-4b42-aca1-359920d59b30",
   "metadata": {},
   "outputs": [],
   "source": [
    "faces.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4be23dd1",
   "metadata": {},
   "source": [
    "# creating training, test and validate datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15351fd3",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "377bcc80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------------------------------\n",
    "# Below is the part where we create train, validation, and test splits from the DataFrame\n",
    "# ------------------------------------------------------------------------------------\n",
    "\n",
    "def create_splits(faces, test_ratio=0.2, val_ratio=0.1, random_seed=42):\n",
    "    \"\"\"\n",
    "    Given a DataFrame 'faces', split into train, val, test sets.\n",
    "    \n",
    "    test_ratio: fraction of the data to be held out for testing\n",
    "    val_ratio: fraction of the *remaining* data to be used for validation\n",
    "    random_seed: for reproducibility\n",
    "    \"\"\"\n",
    "    # 1. Split off the test set first\n",
    "    df_trainval, df_test = train_test_split(\n",
    "        faces,\n",
    "        test_size=test_ratio,\n",
    "        random_state=random_seed,\n",
    "        shuffle=True,\n",
    "        stratify=faces['Y']  # optional, if you want stratified splits by label\n",
    "    )\n",
    "    \n",
    "    # 2. Of what's left (trainval), split out the validation set\n",
    "    #    We want val_ratio *of the trainval set*.\n",
    "    #    For example, if test_ratio=0.2, we have 80% left,\n",
    "    #    we can do val_ratio=0.1 of the original => 0.1 / 0.8 = 0.125\n",
    "    #    or you can interpret val_ratio as a fraction of the entire dataset.\n",
    "    #    Here we'll assume val_ratio is the fraction of *the original dataset*,\n",
    "    #    so we convert it to fraction of trainval via `val_ratio / (1 - test_ratio)`.\n",
    "    relative_val_ratio = val_ratio / (1 - test_ratio)  # fraction of trainval\n",
    "    df_train, df_val = train_test_split(\n",
    "        df_trainval,\n",
    "        test_size=relative_val_ratio,\n",
    "        random_state=random_seed,\n",
    "        shuffle=True,\n",
    "        stratify=df_trainval['Y']\n",
    "    )\n",
    "    \n",
    "    return df_train, df_val, df_test\n",
    "\n",
    "df_faces = faces\n",
    "if not df_faces.empty:\n",
    "    # Create train/val/test splits: 70% train, 10% val, 20% test (example)\n",
    "    # => test_ratio=0.2, val_ratio=0.1\n",
    "    # This means:\n",
    "    #   test = 20% of total\n",
    "    #   val = 10% of total\n",
    "    #   train = 70% of total\n",
    "    df_train, df_val, df_test = create_splits(df_faces, test_ratio=0.2, val_ratio=0.1)\n",
    "    \n",
    "    print(\"\\nSplit sizes:\")\n",
    "    print(\"Train set:\", len(df_train))\n",
    "    print(\"Val set:\", len(df_val))\n",
    "    print(\"Test set:\", len(df_test))\n",
    "    \n",
    "    # OPTIONAL: If you want them as arrays\n",
    "    # Convert flattened features (X) to a 2D numpy array\n",
    "    X_train = np.stack(df_train['X'].values)\n",
    "    y_train = df_train['Y'].values\n",
    "    \n",
    "    X_val = np.stack(df_val['X'].values)\n",
    "    y_val = df_val['Y'].values\n",
    "    \n",
    "    X_test = np.stack(df_test['X'].values)\n",
    "    y_test = df_test['Y'].values\n",
    "\n",
    "    X_train = X_train.reshape(-1, 170, 170, 1)\n",
    "    X_val = X_val.reshape(-1, 170, 170, 1)\n",
    "    X_test = X_test.reshape(-1, 170, 170, 1)\n",
    "\n",
    "    \n",
    "    # Now you have train, val, test in DataFrame form (df_train, df_val, df_test)\n",
    "    # or in array form (X_train, y_train, X_val, y_val, X_test, y_test).\n",
    "    print(f\"X_train shape: {X_train.shape}, y_train shape: {y_train.shape}\")\n",
    "    print(f\"X_val shape:   {X_val.shape},   y_val shape:   {y_val.shape}\")\n",
    "    print(f\"X_test shape:  {X_test.shape},  y_test shape:  {y_test.shape}\")\n",
    "else:\n",
    "    print(\"No faces found. Exiting.\")\n",
    "      "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05696b38",
   "metadata": {},
   "source": [
    "# setting up the model, training the model, and evaluating it\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7c8256a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def squeeze_excite_block(input_tensor, ratio=16):\n",
    "    \"\"\"Squeeze and Excitation block.\"\"\"\n",
    "    channels = int(input_tensor.shape[-1])\n",
    "    se = GlobalAveragePooling2D()(input_tensor)\n",
    "    se = Reshape((1, 1, channels))(se)\n",
    "    se = Dense(channels // ratio, activation='relu', use_bias=False)(se)\n",
    "    se = Dense(channels, activation='sigmoid', use_bias=False)(se)\n",
    "    return multiply([input_tensor, se])\n",
    "\n",
    "def create_model_with_attention(input_shape, num_classes):\n",
    "    # Define input\n",
    "    inputs = tf.keras.Input(shape=input_shape)\n",
    "\n",
    "    # Conv block 1\n",
    "    x = Conv2D(32, (3,3), activation='relu', padding='valid')(inputs)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = squeeze_excite_block(x)   # Directly call the SE function\n",
    "    x = MaxPooling2D(pool_size=(2,2))(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "\n",
    "    # Conv block 2\n",
    "    x = Conv2D(64, (3,3), activation='relu', padding='valid')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = squeeze_excite_block(x) \n",
    "    x = MaxPooling2D(pool_size=(2,2))(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "\n",
    "    # Classifier\n",
    "    x = Flatten()(x)\n",
    "    x = Dense(128, activation='relu')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dropout(0.4)(x)\n",
    "    outputs = Dense(num_classes, activation='softmax')(x)\n",
    "\n",
    "    # Build the Model\n",
    "    model = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "    model.compile(\n",
    "        optimizer='adam',\n",
    "        loss='categorical_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "\n",
    "    return model\n",
    "\n",
    "def create_model(input_shape, num_classes):\n",
    "    \"\"\"\n",
    "    Builds a CNN for face classification.\n",
    "    \n",
    "    Args:\n",
    "        input_shape (tuple): Shape of a single input image, e.g. (170, 170, 1) for grayscale\n",
    "        num_classes (int): Number of output classes (e.g., 2 if squint vs. not squint)\n",
    "\n",
    "    Returns:\n",
    "        A compiled Keras model.\n",
    "    \"\"\"\n",
    "    model = Sequential([\n",
    "        Conv2D(32, (3, 3), activation='relu', input_shape=input_shape),\n",
    "        BatchNormalization(),\n",
    "        MaxPooling2D(pool_size=(2, 2)),\n",
    "        Dropout(0.25),\n",
    "\n",
    "        Conv2D(64, (3, 3), activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        MaxPooling2D(pool_size=(2, 2)),\n",
    "        Dropout(0.25),\n",
    "\n",
    "        Flatten(),\n",
    "        Dense(128, activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        Dropout(0.5),\n",
    "        \n",
    "        Dense(num_classes, activation='softmax')\n",
    "    ])\n",
    "    model.compile(\n",
    "        optimizer='adam', \n",
    "        loss='categorical_crossentropy', \n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    return model\n",
    "\n",
    "def train_model(model, X_train, y_train, validation_data=None, epochs=20):\n",
    "    \"\"\"\n",
    "    Trains the CNN model using X_train, y_train, and optionally validation_data=(X_val, y_val).\n",
    "    \n",
    "    Args:\n",
    "        model (keras.Model): Compiled Keras model.\n",
    "        X_train: Training data (NumPy array or a generator-like object).\n",
    "        y_train: Training labels (NumPy array). If X_train is a generator, y_train can be None.\n",
    "        validation_data (tuple or generator): Either (X_val, y_val) if using NumPy arrays,\n",
    "                                             or a generator-like object with 'samples' and 'batch_size'.\n",
    "        epochs (int): Number of epochs to train.\n",
    "\n",
    "    Returns:\n",
    "        history: Keras History object with training curves.\n",
    "    \"\"\"\n",
    "    from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "\n",
    "    # Define callbacks\n",
    "    callbacks = [\n",
    "        ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=2, min_lr=0.00001),\n",
    "        EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
    "    ]\n",
    "\n",
    "    # Figure out steps_per_epoch if X_train is a generator-like object\n",
    "    if hasattr(X_train, 'samples') and hasattr(X_train, 'batch_size'):\n",
    "        steps_per_epoch = X_train.samples // X_train.batch_size\n",
    "    else:\n",
    "        steps_per_epoch = None\n",
    "\n",
    "    # Figure out validation_steps if validation_data is also a generator\n",
    "    validation_steps = None\n",
    "    if validation_data is not None:\n",
    "        if hasattr(validation_data, 'samples') and hasattr(validation_data, 'batch_size'):\n",
    "            validation_steps = validation_data.samples // validation_data.batch_size\n",
    "\n",
    "\n",
    "    # One-hot encode the labels (which are 0 or 1)\n",
    "    y_train_oh = tf.keras.utils.to_categorical(y_train, num_classes=2)\n",
    "    y_val_oh   = tf.keras.utils.to_categorical(y_val, num_classes=2)\n",
    "    y_test_oh  = tf.keras.utils.to_categorical(y_test, num_classes=2)\n",
    "\n",
    "\n",
    "    # Now fit the model\n",
    "    # If X_train, y_train are NumPy arrays, this works\n",
    "    # If X_train is a generator, it expects y_train=None (typical for generators),\n",
    "    #   but we allow it here in case user wants to pass it anyway.\n",
    "    history = model.fit(\n",
    "        X_train, \n",
    "        y_train_oh, \n",
    "        validation_data=(X_val, y_val_oh),\n",
    "        epochs=64\n",
    "    )\n",
    "    \n",
    "    return history\n",
    "\n",
    "def evaluate_model(model, test_data):\n",
    "    \"\"\"\n",
    "    Evaluates the model on test_data and prints the loss & accuracy.\n",
    "    \n",
    "    Args:\n",
    "        model (keras.Model): Trained Keras model.\n",
    "        test_data: Test dataset (ImageDataGenerator, tf.data.Dataset, or (x_test, y_test)).\n",
    "    \"\"\"\n",
    "    # If it's an ImageDataGenerator, we can do steps = test_data.samples // test_data.batch_size\n",
    "    # If it's tf.data or NumPy arrays, you can omit steps.\n",
    "    \n",
    "    steps = None\n",
    "    if hasattr(test_data, \"samples\") and hasattr(test_data, \"batch_size\"):\n",
    "        steps = test_data.samples // test_data.batch_size\n",
    "    \n",
    "    scores = model.evaluate(test_data, steps=steps)\n",
    "    print(f\"Test Loss: {scores[0]}\")\n",
    "    print(f\"Test Accuracy: {scores[1]}\")\n",
    "\n",
    "#\n",
    "# EXAMPLE USAGE (assuming you have train_data, val_data, test_data):\n",
    "#\n",
    "model = create_model_with_attention(input_shape=(170,170,1), num_classes=2)\n",
    "\n",
    "callbacks = [\n",
    "    ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=3, min_lr=0.00001),\n",
    "    EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "]\n",
    "\n",
    "history = train_model(model, X_train, y_train, validation_data=(X_val, y_val))\n",
    "#evaluate_model(model, df_test)\n",
    "#\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d9f375f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50a8e369",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_training_history(history):\n",
    "    \"\"\"\n",
    "    Plots the training and validation accuracy and loss curves\n",
    "    from a Keras History object.\n",
    "    \"\"\"\n",
    "    # Use a Seaborn style/theme for a \"fancy\" look\n",
    "    sns.set_style(\"darkgrid\") \n",
    "\n",
    "    # Extract values for accuracy and loss\n",
    "    acc = history.history['accuracy']\n",
    "    val_acc = history.history['val_accuracy']\n",
    "    loss = history.history['loss']\n",
    "    val_loss = history.history['val_loss']\n",
    "\n",
    "    # Create an array of epoch indices (1-based)\n",
    "    epochs = range(1, len(acc) + 1)\n",
    "\n",
    "    # Create a figure with two subplots: Accuracy & Loss\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "    # --- Accuracy Plot ---\n",
    "    axes[0].plot(epochs, acc, label='Training Accuracy', marker='o', color='blue')\n",
    "    axes[0].plot(epochs, val_acc, label='Validation Accuracy', marker='o', color='orange')\n",
    "    axes[0].set_title('Training & Validation Accuracy', fontsize=14)\n",
    "    axes[0].set_xlabel('Epoch', fontsize=12)\n",
    "    axes[0].set_ylabel('Accuracy', fontsize=12)\n",
    "    axes[0].legend()\n",
    "    \n",
    "    # --- Loss Plot ---\n",
    "    axes[1].plot(epochs, loss, label='Training Loss', marker='o', color='red')\n",
    "    axes[1].plot(epochs, val_loss, label='Validation Loss', marker='o', color='green')\n",
    "    axes[1].set_title('Training & Validation Loss', fontsize=14)\n",
    "    axes[1].set_xlabel('Epoch', fontsize=12)\n",
    "    axes[1].set_ylabel('Loss', fontsize=12)\n",
    "    axes[1].legend()\n",
    "\n",
    "    # Add a main title for the entire figure\n",
    "    fig.suptitle('Model Performance Over Epochs', fontsize=16, fontweight='bold')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c031ea0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_training_history(history)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
